{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b443796",
   "metadata": {},
   "source": [
    "# Stage 1 - Make and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b57419c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.870207</td>\n",
       "      <td>1.393313</td>\n",
       "      <td>339.856861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>578.634541</td>\n",
       "      <td>582.206049</td>\n",
       "      <td>472.369702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-999.638201</td>\n",
       "      <td>-999.427704</td>\n",
       "      <td>-983.123838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-496.774421</td>\n",
       "      <td>-501.091755</td>\n",
       "      <td>9.998594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.168013</td>\n",
       "      <td>2.809366</td>\n",
       "      <td>425.599138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>501.408226</td>\n",
       "      <td>517.594201</td>\n",
       "      <td>740.628323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.711480</td>\n",
       "      <td>999.982514</td>\n",
       "      <td>999.982514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x             y        output\n",
       "count  10000.000000  10000.000000  10000.000000\n",
       "mean       2.870207      1.393313    339.856861\n",
       "std      578.634541    582.206049    472.369702\n",
       "min     -999.638201   -999.427704   -983.123838\n",
       "25%     -496.774421   -501.091755      9.998594\n",
       "50%        4.168013      2.809366    425.599138\n",
       "75%      501.408226    517.594201    740.628323\n",
       "max      999.711480    999.982514    999.982514"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "## dataset generation\n",
    "# lets say we want to train a function that returns max(x,y)\n",
    "\n",
    "input_data = pd.DataFrame({\n",
    "    'x': np.random.uniform(-1000, 1000, 10000),\n",
    "    'y': np.random.uniform(-1000, 1000, 10000)\n",
    "})\n",
    "output_data = pd.DataFrame({\n",
    "    'output': np.maximum(input_data['x'], input_data['y'])\n",
    "})\n",
    "\n",
    "\n",
    "df = pd.concat([input_data, output_data], axis=1)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bd9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.1773576736450195\n",
      "Epoch 1, Loss: 0.21251170337200165\n",
      "Epoch 2, Loss: 0.2396649420261383\n",
      "Epoch 3, Loss: 0.14902222156524658\n",
      "Epoch 4, Loss: 0.11189847439527512\n",
      "Epoch 5, Loss: 0.08143521100282669\n",
      "Epoch 6, Loss: 0.07565190643072128\n",
      "Epoch 7, Loss: 0.06692548841238022\n",
      "Epoch 8, Loss: 0.043258484452962875\n",
      "Epoch 9, Loss: 0.036197226494550705\n",
      "Epoch 10, Loss: 0.054438211023807526\n",
      "Epoch 11, Loss: 0.02050456404685974\n",
      "Epoch 12, Loss: 0.013617522083222866\n",
      "Epoch 13, Loss: 0.020160654559731483\n",
      "Epoch 14, Loss: 0.12236356735229492\n",
      "Epoch 15, Loss: 0.006516922730952501\n",
      "Epoch 16, Loss: 8.002128601074219\n",
      "Epoch 17, Loss: 1.2831875085830688\n",
      "Epoch 18, Loss: 3.0018365383148193\n",
      "Epoch 19, Loss: 0.2687535285949707\n",
      "Epoch 20, Loss: 4.842458724975586\n",
      "Epoch 21, Loss: 0.012875671498477459\n",
      "Epoch 22, Loss: 0.06681492924690247\n",
      "Epoch 23, Loss: 10.468391418457031\n",
      "Epoch 24, Loss: 0.3817182779312134\n",
      "Epoch 25, Loss: 0.20693449676036835\n",
      "Epoch 26, Loss: 0.38488632440567017\n",
      "Epoch 27, Loss: 0.03862190246582031\n",
      "Epoch 28, Loss: 9.86783218383789\n",
      "Epoch 29, Loss: 0.00923510268330574\n",
      "Epoch 30, Loss: 0.0007621269905939698\n",
      "Epoch 31, Loss: 0.0012247527483850718\n",
      "Epoch 32, Loss: 0.0002934785152319819\n",
      "Epoch 33, Loss: 0.28386926651000977\n",
      "Epoch 34, Loss: 0.03417794033885002\n",
      "Epoch 35, Loss: 0.05917064845561981\n",
      "Epoch 36, Loss: 0.009071740321815014\n",
      "Epoch 37, Loss: 0.0007842817576602101\n",
      "Epoch 38, Loss: 0.004364518448710442\n",
      "Epoch 39, Loss: 0.06682231277227402\n",
      "Epoch 40, Loss: 0.8881921768188477\n",
      "Epoch 41, Loss: 0.04652979224920273\n",
      "Epoch 42, Loss: 1.7283319234848022\n",
      "Epoch 43, Loss: 0.002385440981015563\n",
      "Epoch 44, Loss: 0.002186621306464076\n",
      "Epoch 45, Loss: 0.04229778051376343\n",
      "Epoch 46, Loss: 0.07308083772659302\n",
      "Epoch 47, Loss: 0.011247750371694565\n",
      "Epoch 48, Loss: 0.0022163456305861473\n",
      "Epoch 49, Loss: 0.002445332705974579\n",
      "Epoch 50, Loss: 0.0076340618543326855\n",
      "Epoch 51, Loss: 0.07667229324579239\n",
      "Epoch 52, Loss: 0.25039443373680115\n",
      "Epoch 53, Loss: 0.006806022021919489\n",
      "Epoch 54, Loss: 0.0007081517833285034\n",
      "Epoch 55, Loss: 0.050274938344955444\n",
      "Epoch 56, Loss: 0.26524919271469116\n",
      "Epoch 57, Loss: 0.0011457810178399086\n",
      "Epoch 58, Loss: 0.0018534769769757986\n",
      "Epoch 59, Loss: 0.23823173344135284\n",
      "Epoch 60, Loss: 1.9536281824111938\n",
      "Epoch 61, Loss: 0.03507603332400322\n",
      "Epoch 62, Loss: 0.036907702684402466\n",
      "Epoch 63, Loss: 0.14732861518859863\n",
      "Epoch 64, Loss: 0.26705116033554077\n",
      "Epoch 65, Loss: 0.021395724266767502\n",
      "Epoch 66, Loss: 0.0005354346358217299\n",
      "Epoch 67, Loss: 0.10703355073928833\n",
      "Epoch 68, Loss: 0.29619815945625305\n",
      "Epoch 69, Loss: 3.3025858402252197\n",
      "Epoch 70, Loss: 0.9534316062927246\n",
      "Epoch 71, Loss: 0.0035318201407790184\n",
      "Epoch 72, Loss: 0.10538718104362488\n",
      "Epoch 73, Loss: 0.059922877699136734\n",
      "Epoch 74, Loss: 0.07036954909563065\n",
      "Epoch 75, Loss: 0.06531503051519394\n",
      "Epoch 76, Loss: 0.2564498484134674\n",
      "Epoch 77, Loss: 8.852372169494629\n",
      "Epoch 78, Loss: 0.008715551346540451\n",
      "Epoch 79, Loss: 0.003236992284655571\n",
      "Epoch 80, Loss: 0.03901806101202965\n",
      "Epoch 81, Loss: 0.03586968407034874\n",
      "Epoch 82, Loss: 17.553668975830078\n",
      "Epoch 83, Loss: 0.009342278353869915\n",
      "Epoch 84, Loss: 0.0007227064343169332\n",
      "Epoch 85, Loss: 0.0008841344388201833\n",
      "Epoch 86, Loss: 0.24392905831336975\n",
      "Epoch 87, Loss: 7.188841342926025\n",
      "Epoch 88, Loss: 0.011906606145203114\n",
      "Epoch 89, Loss: 0.00036981419543735683\n",
      "Epoch 90, Loss: 0.006002810783684254\n",
      "Epoch 91, Loss: 0.29116469621658325\n",
      "Epoch 92, Loss: 0.356983482837677\n",
      "Epoch 93, Loss: 0.0020444004330784082\n",
      "Epoch 94, Loss: 0.0014475580537691712\n",
      "Epoch 95, Loss: 0.7127121686935425\n",
      "Epoch 96, Loss: 0.025376880541443825\n",
      "Epoch 97, Loss: 0.4036348760128021\n",
      "Epoch 98, Loss: 0.2542688548564911\n",
      "Epoch 99, Loss: 0.09446802735328674\n"
     ]
    }
   ],
   "source": [
    "# model definition and training\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(2, 10)\n",
    "        self.linear2 = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    # this method is necessary for the model to be evaluated by poly-lithic\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        # x will be a dicrt of keys and values\n",
    "        # {\"x\": x, \"y\": y}\n",
    "        input_tensor = torch.tensor([x['x'], x['y']], dtype=torch.float32)\n",
    "        # you may want to do somethinf more complex here\n",
    "        output_tensor = self.forward(input_tensor)\n",
    "        # return a dictionary of keys and values\n",
    "        return {\"output\": output_tensor.item()}        \n",
    "    \n",
    "# model training\n",
    "model = SimpleModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "batch_size = 32\n",
    "\n",
    "# convert data to torch tensors\n",
    "X = torch.tensor(df[['x', 'y']].values, dtype=torch.float32)\n",
    "y = torch.tensor(df[['output']].values, dtype=torch.float32)\n",
    "# training loop\n",
    "for epoch in range(100):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        X_batch = X[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        # backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "    \n",
    "# save the model\n",
    "torch.save(model.state_dict(), 'local/model.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedb6fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4254.9275\n",
      "Input: [ 98.19370686 545.76953676], Predicted: 545.989990234375, Actual: 545.76953125\n",
      "Input: [-33.56557292  78.23007306], Predicted: 78.2187271118164, Actual: 78.23007202148438\n",
      "Input: [445.50908726 738.20504473], Predicted: 738.5706176757812, Actual: 738.2050170898438\n",
      "Input: [-224.36883391 -855.20430802], Predicted: -223.91690063476562, Actual: -224.36883544921875\n",
      "Input: [  -7.1227906  -948.68151075], Predicted: -7.091699600219727, Actual: -7.122790813446045\n",
      "Input: [ 867.89452037 -960.86086584], Predicted: 865.7548217773438, Actual: 867.89453125\n",
      "Input: [  -1.53737919 -874.7682752 ], Predicted: -1.517396330833435, Actual: -1.5373791456222534\n",
      "Input: [-789.66240356  864.50937532], Predicted: 864.3361206054688, Actual: 864.5093994140625\n",
      "Input: [878.03037571 788.22255001], Predicted: 876.9638671875, Actual: 878.0303955078125\n",
      "Input: [-272.58051688  796.14193243], Predicted: 796.4116821289062, Actual: 796.1419067382812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbm96348/nfs_home/ml_env/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "test_data = pd.DataFrame({\n",
    "    'x': np.random.uniform(-1000, 1000, 100),\n",
    "    'y': np.random.uniform(-1000, 1000, 100)\n",
    "})\n",
    "test_X = torch.tensor(test_data[['x', 'y']].values, dtype=torch.float32)\n",
    "test_y = torch.tensor(np.maximum(test_data['x'], test_data['y']), dtype=torch.float32)\n",
    "test_y_pred = model(test_X)\n",
    "test_loss = loss_fn(test_y_pred, test_y)\n",
    "print(f'Test Loss: {test_loss.item()/len(test_X)}')\n",
    "\n",
    "# print sample\n",
    "for i in range(10):\n",
    "    print(f\"Input: {test_data.iloc[i].values}, Predicted: {test_y_pred[i].item()}, Actual: {test_y[i].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b5966",
   "metadata": {},
   "source": [
    "# Stage 2a - Write a poly-lithic compatible model  - from local file system\n",
    "\n",
    "Look inside `examples/base/local/model_definition.py`\n",
    "\n",
    "The file is composed of a model factory and a model definition. Which we point to in the deployment.yaml file.\n",
    "\n",
    "\n",
    "Model definition as beofre:\n",
    "\n",
    "``` python\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(2, 10)\n",
    "        self.linear2 = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    # this method is necessary for the model to be evaluated by poly-lithic\n",
    "    \n",
    "    def evaluate(self, x: dict) -> dict:\n",
    "        # x will be a dicrt of keys and values\n",
    "        # {\"x\": x, \"y\": y}\n",
    "        input_tensor = torch.tensor([x['x'], x['y']], dtype=torch.float32)\n",
    "        # you may want to do somethinf more complex here\n",
    "        output_tensor = self.forward(input_tensor)\n",
    "        # return a dictionary of keys and values\n",
    "        return {\"output\": output_tensor.item()}\n",
    "```\n",
    "\n",
    "Model factory:\n",
    "\n",
    "``` python\n",
    "class ModelFactory:\n",
    "    \n",
    "    # can do more complex things here but we will just load the model from a locally saved file\n",
    "    def __init__(self):\n",
    "        self.model = SimpleModel()\n",
    "        self.model = self.model.load_state_dict(torch.load('model.pth'))\n",
    "        # other magic init stuff here\n",
    "        print(\"ModelFactory initialized\")\n",
    "    \n",
    "    # this method is necessary for the model to be retrieved by poly-lithic\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b9cc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH set to: /home/gbm96348/nfs_home/lume-deployment\n",
      "Warning: Model file 'examples/base/local/model.pth' not found. Using untrained model.\n",
      "ModelFactory initialized\n",
      "Input: {'x': -20, 'y': 1000.0}, Output: {'output': -169.1890869140625}\n"
     ]
    }
   ],
   "source": [
    "# lets check our import works\n",
    "from local.model_definition import ModelFactory\n",
    "\n",
    "factory = ModelFactory()\n",
    "\n",
    "model = factory.get_model()\n",
    "\n",
    "\n",
    "sample_input = {\n",
    "    \"x\": -20,\n",
    "    \"y\": 1000.0\n",
    "}\n",
    "sample_output = model.evaluate(sample_input)\n",
    "print(f\"Input: {sample_input}, Output: {sample_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad617072",
   "metadata": {},
   "source": [
    "In this case our `deployment_config.yaml` file will look like this:\n",
    "\n",
    "``` yaml\n",
    "deployment:\n",
    "  type: \"continuous\"\n",
    "  rate: 1 #seconds\n",
    "\n",
    "modules: \n",
    "  p4p_server:\n",
    "    name: \"p4p_server\"\n",
    "    type: \"interface.p4p_server\"\n",
    "    pub: \n",
    "      - \"in_interface\"\n",
    "    sub: \n",
    "      - \"get_all\"\n",
    "      - \"out_transformer\" # look we can do this now!               \n",
    "    module_args: None # defines what arguments to pass to the module observer, if any this can inform unpacking etc\n",
    "    config: \n",
    "      EPICS_PVA_NAME_SERVERS: \"localhost:5075\"\n",
    "      variables:\n",
    "        ML:LOCAL:TEST_B:\n",
    "          proto: pva\n",
    "          name: ML:LOCAL:TEST_B \n",
    "        ML:LOCAL:TEST_A:\n",
    "          proto: pva\n",
    "          name: ML:LOCAL:TEST_A\n",
    "        ML:LOCAL:TEST_S:\n",
    "          proto: pva\n",
    "          name: ML:LOCAL:TEST_S\n",
    "  \n",
    "  input_transformer:\n",
    "    name: \"input_transformer\"\n",
    "    type: \"transformer.SimpleTransformer\"\n",
    "    pub: \"in_transformer\"\n",
    "    sub: \"in_interface\"\n",
    "    module_args: None\n",
    "    config:\n",
    "      symbols:\n",
    "        - \"ML:LOCAL:TEST_B\"\n",
    "        - \"ML:LOCAL:TEST_A\"\n",
    "      variables:\n",
    "        x: # note this is where we change the name to match what the model expects\n",
    "          formula: \"ML:LOCAL:TEST_A\"\n",
    "        y: \n",
    "          formula: \"ML:LOCAL:TEST_B\"\n",
    "  model:\n",
    "    name: \"model\"\n",
    "    type: \"model.SimpleModel\"\n",
    "    pub: \"model\"\n",
    "    sub: \"in_transformer\"\n",
    "    module_args: None\n",
    "    config:\n",
    "      type: \"LocalModelGetter\"\n",
    "      args: \n",
    "        model_path: \"examples/base/local/model_definition.py\"           # path to the model definition\n",
    "        model_factory_class: \"ModelFactory\"                             # class that you use to create the model\n",
    "      variables:\n",
    "        max:\n",
    "          type: \"scalar\"\n",
    "  \n",
    "  output_transformer:\n",
    "    name: \"output_transformer\"\n",
    "    type: \"transformer.SimpleTransformer\"\n",
    "    pub: \"out_transformer\"\n",
    "    sub: \"model\"\n",
    "    module_args: \n",
    "      unpack_data: True\n",
    "    config:\n",
    "      symbols:\n",
    "        - \"output\"\n",
    "      variables:\n",
    "        ML:LOCAL:TEST_S:\n",
    "          formula: \"output\"\n",
    "```\n",
    "\n",
    "Then to launch the model we can use the following command:\n",
    "\n",
    "``` bash\n",
    "pl --publish -c examples/base/local/deployment_config.yaml`\n",
    "```        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca2855",
   "metadata": {},
   "source": [
    "# Stage 2b - Write a poly-lithic compatible model  - from mlflow\n",
    "\n",
    "WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
